{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585fd1ad-848d-43f9-8b77-da3502d1cddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "النصوص الأصلية:\n",
      "                                          نص\n",
      "0        أنا أحب تعلم معالجة اللغات الطبيعية\n",
      "1              بايثون تسهل التعامل مع النصوص\n",
      "2  تحليل النصوص مهم جدًا في الذكاء الاصطناعي\n",
      "\n",
      "\n",
      "بعد التنظيف:\n",
      "                                          نص  \\\n",
      "0        أنا أحب تعلم معالجة اللغات الطبيعية   \n",
      "1              بايثون تسهل التعامل مع النصوص   \n",
      "2  تحليل النصوص مهم جدًا في الذكاء الاصطناعي   \n",
      "\n",
      "                                   نص_منظف  \n",
      "0      أنا أحب تعلم معالجة اللغات الطبيعية  \n",
      "1            بايثون تسهل التعامل مع النصوص  \n",
      "2  تحليل النصوص مهم جدا في الذكا الاصطناعي  \n",
      "\n",
      "\n",
      "بعد استخراج الميزات اليدوية:\n",
      "                                          نص  \\\n",
      "0        أنا أحب تعلم معالجة اللغات الطبيعية   \n",
      "1              بايثون تسهل التعامل مع النصوص   \n",
      "2  تحليل النصوص مهم جدًا في الذكاء الاصطناعي   \n",
      "\n",
      "                                   نص_منظف  عدد_الكلمات  عدد_الجمل  \\\n",
      "0      أنا أحب تعلم معالجة اللغات الطبيعية            6          1   \n",
      "1            بايثون تسهل التعامل مع النصوص            5          1   \n",
      "2  تحليل النصوص مهم جدا في الذكا الاصطناعي            7          1   \n",
      "\n",
      "   عدد_الحروف  عدد_الحروف_الكبيرة  \n",
      "0          35                   0  \n",
      "1          29                   0  \n",
      "2          41                   0  \n",
      "\n",
      "\n",
      "scikit-learn غير مثبت، سيتم استخدام الميزات اليدوية فقط.\n",
      "تم حفظ الملف CSV بنجاح.\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# الدرس 02 – Bag of Words و الميزات اليدوية\n",
    "# ====================================\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------\n",
    "# 1️⃣ تحضير البيانات (باللغة العربية)\n",
    "# ------------------------------\n",
    "data = {\n",
    "    \"نص\": [\n",
    "        \"أنا أحب تعلم معالجة اللغات الطبيعية\",\n",
    "        \"بايثون تسهل التعامل مع النصوص\",\n",
    "        \"تحليل النصوص مهم جدًا في الذكاء الاصطناعي\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"النصوص الأصلية:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2️⃣ تنظيف النصوص\n",
    "# ------------------------------\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # تحويل كل الحروف إلى صغيرة\n",
    "    text = re.sub(r'[^أ-ي\\s]', '', text)  # إزالة الرموز والأرقام\n",
    "    return text\n",
    "\n",
    "df['نص_منظف'] = df['نص'].apply(clean_text)\n",
    "print(\"بعد التنظيف:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3️⃣ استخراج الميزات اليدوية\n",
    "# ------------------------------\n",
    "def manual_features(text):\n",
    "    tokens = text.split()  # تقسيم الكلمات\n",
    "    sentences = text.split('،')  # تقريب عدد الجمل باستخدام الفاصلة\n",
    "    return pd.Series({\n",
    "        \"عدد_الكلمات\": len(tokens),\n",
    "        \"عدد_الجمل\": len(sentences),\n",
    "        \"عدد_الحروف\": len(text),\n",
    "        \"عدد_الحروف_الكبيرة\": sum(1 for c in text if c.isupper())\n",
    "    })\n",
    "\n",
    "df = pd.concat([df, df['نص'].apply(manual_features)], axis=1)\n",
    "print(\"بعد استخراج الميزات اليدوية:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ------------------------------\n",
    "# 4️⃣ إنشاء Bag of Words\n",
    "# ------------------------------\n",
    "# إذا كان sklearn موجود يمكنك استخدامه\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df['نص_منظف'])\n",
    "    df_bow = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    df_final = pd.concat([df, df_bow], axis=1)\n",
    "    print(\"تم إنشاء Bag of Words ودمجها مع الميزات اليدوية:\")\n",
    "    print(df_final)\n",
    "except ImportError:\n",
    "    print(\"scikit-learn غير مثبت، سيتم استخدام الميزات اليدوية فقط.\")\n",
    "    df_final = df\n",
    "\n",
    "# ------------------------------\n",
    "# 5️⃣ حفظ النتائج (اختياري)\n",
    "# ------------------------------\n",
    "df_final.to_csv(\"درس02_Bag_of_Words_Manual_عربي.csv\", index=False)\n",
    "print(\"تم حفظ الملف CSV بنجاح.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b221f75-4d49-4292-b817-86df21c0ce9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
